{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Binary tree with decision tree semantics and ASCII visualization.\"\"\"\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"A decision tree node.\"\"\"\n",
    "\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def debug(self, feature_names, class_names, show_details):\n",
    "        \"\"\"Print an ASCII visualization of the tree.\"\"\"\n",
    "        lines, _, _, _ = self._debug_aux(\n",
    "            feature_names, class_names, show_details, root=True\n",
    "        )\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "\n",
    "    def _debug_aux(self, feature_names, class_names, show_details, root=False):\n",
    "        # See https://stackoverflow.com/a/54074933/1143396 for similar code.\n",
    "        is_leaf = not self.right\n",
    "        if is_leaf:\n",
    "            lines = [class_names[self.predicted_class]]\n",
    "        else:\n",
    "            lines = [\n",
    "                \"{} < {:.2f}\".format(feature_names[self.feature_index], self.threshold)\n",
    "            ]\n",
    "        if show_details:\n",
    "            lines += [\n",
    "                \"gini = {:.2f}\".format(self.gini),\n",
    "                \"samples = {}\".format(self.num_samples),\n",
    "                str(self.num_samples_per_class),\n",
    "            ]\n",
    "        width = max(len(line) for line in lines)\n",
    "        height = len(lines)\n",
    "        if is_leaf:\n",
    "            lines = [\"║ {:^{width}} ║\".format(line, width=width) for line in lines]\n",
    "            lines.insert(0, \"╔\" + \"═\" * (width + 2) + \"╗\")\n",
    "            lines.append(\"╚\" + \"═\" * (width + 2) + \"╝\")\n",
    "        else:\n",
    "            lines = [\"│ {:^{width}} │\".format(line, width=width) for line in lines]\n",
    "            lines.insert(0, \"┌\" + \"─\" * (width + 2) + \"┐\")\n",
    "            lines.append(\"└\" + \"─\" * (width + 2) + \"┘\")\n",
    "            lines[-2] = \"┤\" + lines[-2][1:-1] + \"├\"\n",
    "        width += 4  # for padding\n",
    "\n",
    "        if is_leaf:\n",
    "            middle = width // 2\n",
    "            lines[0] = lines[0][:middle] + \"╧\" + lines[0][middle + 1 :]\n",
    "            return lines, width, height, middle\n",
    "\n",
    "        # If not a leaf, must have two children.\n",
    "        left, n, p, x = self.left._debug_aux(feature_names, class_names, show_details)\n",
    "        right, m, q, y = self.right._debug_aux(feature_names, class_names, show_details)\n",
    "        top_lines = [n * \" \" + line + m * \" \" for line in lines[:-2]]\n",
    "        # fmt: off\n",
    "        middle_line = x * \" \" + \"┌\" + (n - x - 1) * \"─\" + lines[-2] + y * \"─\" + \"┐\" + (m - y - 1) * \" \"\n",
    "        bottom_line = x * \" \" + \"│\" + (n - x - 1) * \" \" + lines[-1] + y * \" \" + \"│\" + (m - y - 1) * \" \"\n",
    "        # fmt: on\n",
    "        if p < q:\n",
    "            left += [n * \" \"] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * \" \"] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = (\n",
    "            top_lines\n",
    "            + [middle_line, bottom_line]\n",
    "            + [a + width * \" \" + b for a, b in zipped_lines]\n",
    "        )\n",
    "        middle = n + width // 2\n",
    "        if not root:\n",
    "            lines[0] = lines[0][:middle] + \"┴\" + lines[0][middle + 1 :]\n",
    "        return lines, n + m + width, max(p, q) + 2 + len(top_lines), middle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--dataset {breast,iris,wifi}]\n",
      "                             [--max_depth MAX_DEPTH] [--hide_details]\n",
      "                             [--use_sklearn]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\riya garg\\AppData\\Roaming\\jupyter\\runtime\\kernel-2c7ee2a9-c07a-48b8-9f65-50e3a7dba599.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build decision tree classifier.\"\"\"\n",
    "        self.n_classes_ = len(set(y))  # classes are assumed to go from 0 to n-1\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class for X.\"\"\"\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def debug(self, feature_names, class_names, show_details=True):\n",
    "        \"\"\"Print ASCII visualization of decision tree.\"\"\"\n",
    "        self.tree_.debug(feature_names, class_names, show_details)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        \"\"\"Compute Gini impurity of a non-empty node.\n",
    "\n",
    "        Gini impurity is defined as Σ p(1-p) over all classes, with p the frequency of a\n",
    "        class within the node. Since Σ p = 1, this is equivalent to 1 - Σ p^2.\n",
    "        \"\"\"\n",
    "        m = y.size\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes_))\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Find the best split for a node.\n",
    "\n",
    "        \"Best\" means that the average impurity of the two children, weighted by their\n",
    "        population, is the smallest possible. Additionally it must be less than the\n",
    "        impurity of the current node.\n",
    "\n",
    "        To find the best split, we loop through all the features, and consider all the\n",
    "        midpoints between adjacent training samples as possible thresholds. We compute\n",
    "        the Gini impurity of the split generated by that particular feature/threshold\n",
    "        pair, and return the pair with smallest impurity.\n",
    "\n",
    "        Returns:\n",
    "            best_idx: Index of the feature for best split, or None if no split is found.\n",
    "            best_thr: Threshold to use for the split, or None if no split is found.\n",
    "        \"\"\"\n",
    "        # Need at least two elements to split a node.\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        # Count of each class in the current node.\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "\n",
    "        # Gini of current node.\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        # Loop through all features.\n",
    "        for idx in range(self.n_features_):\n",
    "            # Sort data along selected feature.\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "\n",
    "            # We could actually split the node according to each feature/threshold pair\n",
    "            # and count the resulting population for each class in the children, but\n",
    "            # instead we compute them in an iterative fashion, making this for loop\n",
    "            # linear rather than quadratic.\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):  # possible split positions\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "\n",
    "                # The Gini impurity of a split is the weighted average of the Gini\n",
    "                # impurity of the children.\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                # The following condition is to make sure we don't try to split two\n",
    "                # points with identical values for that feature, as it is impossible\n",
    "                # (both have to end up on the same side of a split).\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # midpoint\n",
    "\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        \"\"\"Build a decision tree by recursively finding the best split.\"\"\"\n",
    "        # Population for each class in current node. The predicted class is the one with\n",
    "        # largest population.\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = tree.Node(\n",
    "            gini=self._gini(y),\n",
    "            num_samples=y.size,\n",
    "            num_samples_per_class=num_samples_per_class,\n",
    "            predicted_class=predicted_class,\n",
    "        )\n",
    "\n",
    "        # Split recursively until maximum depth is reached.\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        \"\"\"Predict class for a single sample.\"\"\"\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import load_breast_cancer, load_iris\n",
    "    from sklearn.tree import DecisionTreeClassifier as SklearnDecisionTreeClassifier\n",
    "    from sklearn.tree import export_graphviz\n",
    "    from sklearn.utils import Bunch\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Train a decision tree.\")\n",
    "    parser.add_argument(\"--dataset\", choices=[\"breast\", \"iris\", \"wifi\"], default=\"wifi\")\n",
    "    parser.add_argument(\"--max_depth\", type=int, default=1)\n",
    "    parser.add_argument(\"--hide_details\", dest=\"hide_details\", action=\"store_true\")\n",
    "    parser.set_defaults(hide_details=False)\n",
    "    parser.add_argument(\"--use_sklearn\", dest=\"use_sklearn\", action=\"store_true\")\n",
    "    parser.set_defaults(use_sklearn=False)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # 1. Load dataset.\n",
    "    if args.dataset == \"breast\":\n",
    "        dataset = load_breast_cancer()\n",
    "    elif args.dataset == \"iris\":\n",
    "        dataset = load_iris()\n",
    "    elif args.dataset == \"wifi\":\n",
    "        # https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization\n",
    "        df = pd.read_csv(\"wifi_localization.txt\", delimiter=\"\\t\")\n",
    "        data = df.to_numpy()\n",
    "        dataset = Bunch(\n",
    "            data=data[:, :-1],\n",
    "            target=data[:, -1] - 1,\n",
    "            feature_names=[\"Wifi {}\".format(i) for i in range(1, 8)],\n",
    "            target_names=[\"Room {}\".format(i) for i in range(1, 5)],\n",
    "        )\n",
    "    X, y = dataset.data, dataset.target\n",
    "\n",
    "    # 2. Fit decision tree.\n",
    "    if args.use_sklearn:\n",
    "        clf = SklearnDecisionTreeClassifier(max_depth=args.max_depth)\n",
    "    else:\n",
    "        clf = DecisionTreeClassifier(max_depth=args.max_depth)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # 3. Predict.\n",
    "    if args.dataset == \"iris\":\n",
    "        input = [0, 0, 5.0, 1.5]\n",
    "    elif args.dataset == \"wifi\":\n",
    "        input = [-70, 0, 0, 0, -40, 0, 0]\n",
    "    elif args.dataset == \"breast\":\n",
    "        input = [np.random.rand() for _ in range(30)]\n",
    "    pred = clf.predict([input])[0]\n",
    "    print(\"Input: {}\".format(input))\n",
    "    print(\"Prediction: \" + dataset.target_names[pred])\n",
    "\n",
    "    # 4. Visualize.\n",
    "    if args.use_sklearn:\n",
    "        export_graphviz(\n",
    "            clf,\n",
    "            out_file=\"tree.dot\",\n",
    "            feature_names=dataset.feature_names,\n",
    "            class_names=dataset.target_names,\n",
    "            rounded=True,\n",
    "            filled=True,\n",
    "        )\n",
    "        print(\"Done. To convert to PNG, run: dot -Tpng tree.dot -o tree.png\")\n",
    "    else:\n",
    "        clf.debug(\n",
    "            list(dataset.feature_names),\n",
    "            list(dataset.target_names),\n",
    "            not args.hide_details,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
